library(readxl)
library(tidyverse)
library(psych)
library(factoextra)
library(mclust)
library(cluster)

#1.CARGAR BASE 

datos <-read_excel("Tesis/Bases/Tlalpan 2020_LIMPIO_MOD.xlsx", sheet = "datos")
conversion <-read_excel("Tesis/Bases/Tlalpan 2020_LIMPIO_MOD.xlsx", sheet = "conv")

#Crear una nueva base a partir de las 2 hojas anteriores 

datos_largos <- datos %>%
  pivot_longer(
    cols = starts_with("FREC"),
    names_to = "FREC_ID",
    values_to = "frecuencia")

datos_nutri <- datos_largos %>%
  left_join(conversion, by = "FREC_ID")

#2. VERIFICAR NUMERO DE FOLIOS

# Contar cuántas veces se repite cada folio
conteo_folios <- datos_nutri %>%
  group_by(FOLIO) %>%
  summarise(repeticiones = n())

# Ver las primeras filas para revisar
head(conteo_folios)

# Total de folios únicos
total_folios <- n_distinct(datos_nutri$FOLIO)
total_folios

#3. AGRUPAR ALIMENTOS

grupos <- list(
  lacteos = c("FREC001","FREC002","FREC003","FREC004","FREC005","FREC006","FREC007"),
  frutas  = c("FREC008","FREC009","FREC010","FREC011","FREC012","FREC013","FREC014","FREC015",
              "FREC016","FREC017","FREC018","FREC019","FREC020","FREC021","FREC022","FREC023","FREC024","FREC025"),
  carnes  = c("FREC026","FREC027","FREC028","FREC029","FREC030","FREC031","FREC032","FREC033",
              "FREC034","FREC035","FREC036","FREC037","FREC038","FREC039","FREC040","FREC041"),
  verduras= c("FREC042","FREC043","FREC044","FREC045","FREC046","FREC047","FREC048","FREC049",
              "FREC050","FREC051","FREC052","FREC053","FREC054","FREC055","FREC056","FREC057","FREC058"),
  leguminosas = c("FREC059","FREC060","FREC061","FREC062","FREC063"),
  cereales    = c("FREC064","FREC065","FREC066","FREC067","FREC068","FREC069","FREC070","FREC071","FREC072"),
  golosinas   = c("FREC075","FREC076","FREC077","FREC078","FREC079"),
  bebidas     = c("FREC080","FREC081","FREC082","FREC083","FREC084","FREC085","FREC086","FREC087","FREC088","FREC089"),
  grasas      = c("FREC090","FREC091","FREC092","FREC093","FREC094","FREC095","FREC096","FREC097","FREC098","FREC099","FREC100"),
  antojitos   = c("FREC101","FREC102","FREC103","FREC104")
)

#Transformar lista de grupos a dataframe largo
agrupacion <- purrr::imap_dfr(grupos, ~ tibble(FREC_ID = .x, grupo = .y))

#Unir con datos_nutri
datos_nutri <- datos_nutri %>%
  left_join(agrupacion, by = "FREC_ID") %>%
  relocate(grupo, .after = `ALIMENTO`)

#Verificar grupos y número de FREC_ID para cada uno
#FREC_agru <- unlist(grupos)
#FREC_sin_grupo <- setdiff(unique(datos_nutri$FREC_ID), FREC_agru)
#FREC_sin_grupo
#length(FREC_sin_grupo)   # cuántos sin agrupar
#table(FREC_sin_grupo)    # frecuencias (si repiten en varias filas)


#4. CALCULAR CONSUMO DIARIO Y KCAL (CONVERSIÓN DE MACRONUTRIENTES) 

#Calcular consumo diario de cada alimento por participante
datos_nutri <- datos_nutri %>%
  mutate(
    # Consumo en gramos por día
    Prot_g_dia  = frecuencia * `Prot_CFC_(g)`,
    Lip_g_dia   = frecuencia * `Lip_CFC_(g)`,
    CHO_g_dia   = frecuencia * `CHO_CFC_(g)`,
    EtOH_g_dia  = frecuencia * `EtOH_CFC_(g)`,
    
    # Consumo en kcal usando factores de conversión
    Prot_kcal_dia = Prot_g_dia * 4,
    Lip_kcal_dia  = Lip_g_dia * 9,
    CHO_kcal_dia  = CHO_g_dia * 4,
    EtOH_kcal_dia = EtOH_g_dia * 7,
    
    # Total de kcal diarias por alimento 
    Kcal_total_dia = Prot_kcal_dia + Lip_kcal_dia + CHO_kcal_dia + EtOH_kcal_dia
  )

#5. RESUMENES POR PARTICIPANTE (MACROS Y GRUPOS DE ALIMENTOS)

#Desglose de macronutrientes por gramos y Kcal diarios, así como la suma total de energía.

resumen_por_macros <- datos_nutri %>%
  group_by(FOLIO) %>%
  summarise(
    
    #Totales en gramos
    Prot_g_dia_total =sum(Prot_g_dia, na.rm = TRUE),
    Lip_g_dia_total  =sum(Lip_g_dia, na.rm = TRUE),
    CHO_g_dia_total  =sum(CHO_g_dia, na.rm = TRUE),
    EtOH_g_dia_total =sum(EtOH_g_dia, na.rm = TRUE),
    
    #Totales en kcal
    Prot_kcal_dia_total =sum(Prot_kcal_dia, na.rm = TRUE),
    Lip_kcal_dia_total  =sum(Lip_kcal_dia, na.rm = TRUE),
    CHO_kcal_dia_total  =sum(CHO_kcal_dia, na.rm = TRUE),
    EtOH_kcal_dia_total =sum(EtOH_kcal_dia, na.rm = TRUE),
    
    #Energía total de todos los alimentos
    Kcal_total_dia_alimentos =sum(Kcal_total_dia, na.rm = TRUE)
    
  )


#Revisar si hay Energía total igual a cero
resumen_por_macros %>%
filter(is.na(Kcal_total_dia_alimentos) | Kcal_total_dia_alimentos == 0) %>%
select(FOLIO, Kcal_total_dia_alimentos) 


#Desglose por grupo de alimentos, kcal y energía total de cada uno.

resumen_por_grupo <- datos_nutri %>%
  group_by(FOLIO, grupo) %>%
  summarise(
    
    #Totales en gramos
    Prot_g   = sum(Prot_g_dia, na.rm = TRUE),
    Lip_g    = sum(Lip_g_dia, na.rm = TRUE),
    CHO_g    = sum(CHO_g_dia, na.rm = TRUE),
    EtOH_g   = sum(EtOH_g_dia, na.rm = TRUE),
    
    #Totales en kcal
    Prot_kcal_dia =sum(Prot_kcal_dia, na.rm = TRUE),
    Lip_kcal_dia  =sum(Lip_kcal_dia, na.rm = TRUE),
    CHO_kcal_dia  =sum(CHO_kcal_dia, na.rm = TRUE),
    EtOH_kcal_dia =sum(EtOH_kcal_dia, na.rm = TRUE),
    
    #Energía total de todos los alimentos
    Energia_total_grupo = sum(Kcal_total_dia, na.rm = TRUE),
    .groups = "drop"
  ) %>% #Agregar energía total del participante (que ya se tiene)
  
  left_join(
    resumen_por_macros %>%
      select(FOLIO,Kcal_total_dia_alimentos),
    by = "FOLIO"
  ) %>% #Calcular porcentaje de  distribución energética del grupo
  mutate(
    pct_energia_grupo = (Energia_total_grupo/Kcal_total_dia_alimentos)* 100
  )

#Ver resumen
#glimpse(resumen_por_grupo)

#6. ESTANDARIZAR CON Z-SCORE

# Transformar el resumen por grupo a formato ancho: cada grupo es columna
resumen_wide <- resumen_por_grupo %>%
  select(FOLIO, grupo, pct_energia_grupo) %>%
  pivot_wider(names_from = grupo, values_from = pct_energia_grupo)

# Estandarizar con Z-score (media 0, SD 1) por grupo
resumen_z <- resumen_wide %>%
  mutate(across(-FOLIO, ~ scale(.)[,1])) # scale devuelve matriz, usamos [,1] para vector

# Ver resultado
head(resumen_z)

#Revisar NaN que pueden afectar los análisis posteriores
# Detectar valores no finitos
sum(!is.finite(as.matrix(resumen_z[,-1])))

# Reemplazar NaN / Inf / -Inf por 0 en todas las columnas excepto FOLIO
resumen_z <- resumen_z %>%
  mutate(across(-FOLIO, ~ ifelse(!is.finite(.), 0, .)))

# Verificar si quedó limpio
sum(!is.finite(as.matrix(resumen_z[,-1])))

############################################################################################

###ANÁLISIS POR CONGLOMERADOS###

# 1. Preparar datos 

#Revisar la estructura del data.frame
str(resumen_z)

# Excluimos FOLIO si está como primera columna
datos_cluster <- resumen_z %>% select(-FOLIO)

#Excluir datos perdidos
datos_alim <- na.omit(datos_cluster) # borrado de casos perdidos


# 2.Se revisan las tres técnicas para el análisis de clusters

# 2.1. Clustering K-means

#Revisar que las distribución de las variables son comparables o requieren un ajuste en las escalas.
boxplot(datos_alim)

#scale() #De ser necesario se estandariza

#Determinar número de clusters
wss <- (nrow(datos_alim) - 1) * sum(apply(datos_alim, 2, var)) # cálculo de la suma de cuadrados de las varianzas
for (i in 2:15) wss[i] <- sum(kmeans(datos_alim,
                                     centers = i) $ withinss)
plot(1:15, wss, 
     type = "b", 
     xlab = "Cantidad de Clusters",
     ylab="Suma de cuadrados dentro de grupos") #gráfico para la búsqueda del codo
abline(v = codo, col="red", lty=2, lwd=2)

# Detectar codo automático
diff_wss <- diff(wss)
codo <- which.min(diff(diff_wss)) + 1
codo #Se observan 3 clusters

#Asignar a cada caso  a cada uno de los cluster
fit1 <- kmeans(datos_alim, 3) # ajustar 3 clusters a los casos
datos_alim <- data.frame(datos_alim, 
                        fit1 $ cluster) #añadir el cluster al data frame
aggregate(datos_alim, #selección de las variables originales
          by = list(datos_alim $fit1.cluster), #selección de la columna con clusters `k means`
          FUN = mean) # calcular las medias de las variables agregadas por cada cluster
table(datos_alim $ fit1.cluster)

#Usar última variable (fit1.cluster) para avanzar en el análisis de los casos y las variables orignales.
#Analizar el comportamiento de una variable  desagregada entre los 3 grupos o clusters generados previamente.
datos_alim %>%
  ggplot(aes(y = grasas, x = as.factor(fit1.cluster))) +
  geom_boxplot()

#Analizar el comportamiento de dos variables
datos_alim %>%
  ggplot(aes(grasas, carnes)) +
  geom_point(aes(color = as.factor(fit1.cluster)))


# 2.2. Método Jerárquico

#Calcular las distancias existentes entre los casos y agrupar de manera jerárquica.
d <- dist(datos_alim[, 1:4],  #uso del data fame estandarizado
          method = "euclidean") # genera una matriz de distancias
fit2 <- hclust(d, #aplicación del método jerárquico
               method = "ward.D") #criterio de agregación

#Construir dentograma o gráfica de árbol
plot(fit2) # crear dendograma
rect.hclust(fit2, 
            k = 3, #definición de la cantidad de cluster a mapear en el dendograma
            border = "red") #definición del color de las rectas que separan a los clusters

#Integrar casos a cluster jerárquicos
grupos_j <- cutree(fit2, 
                   k = 3) # se distribuyen los casos a partir de los clusters definidos
datos_alim <- data.frame(datos_alim, 
                        grupos_j) # se añaden las clasificaciones jerárquicas al data frame original
table(datos_alim $ grupos_j)

#Descripción de las variables por categorías jerárquicas, para identificar las características internas de cada grupo.

aggregate(datos_cluster, #selección de variables originales
          by = list(datos_alim $ grupos_j), #selección de columna con clusters jerárquicos
          FUN = mean) # calcular las medias de las variables agregadas por cada cluster


# 2.3. Clustering basado en modelos

summary(datos_alim)
apply(datos_alim, 2, sd) #Las variables son casi idénticas (correlación ~ 1), por lo que la matriz de covarianza se vuelve singular y Mclust no puede estimarla.
cor(datos_alim) #Se observa pocas correlaciones, por lo que no se continua con este modelo

#Se basa en los análisis anteriores, en la revisión de resultados gráficos.
BIC <- mclustBIC(datos_alim[, 1:4]) # selección de las variables estandarizadas
plot(BIC)

#Evaluación de los descriptivos de los modelos
mod1 <- Mclust(datos_alim, x = BIC)
summary(mod1, parameters = TRUE)

#Revisar los agrupamientos de manera visual
plot(mod1, what = "classification")
